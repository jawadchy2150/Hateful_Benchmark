{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f836d6b8",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This notebook implements an advanced benchmark of four distinct Vision Language Models (VLMs) on the Hateful Memes Challenge Dataset (HMCD). This version loads the dataset from local files, uses a balanced dataset sample, and evaluates models from four different families to capture classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6f8235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0f59",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset from Local Files & Prepare Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fdeb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'data' \n",
    "ANNOTATION_FILE = os.path.join(DATASET_FOLDER, 'dev.jsonl')\n",
    "IMG_DIR = os.path.join(DATASET_FOLDER, 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9c0cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ANNOTATION_FILE):\n",
    "    print(f\"Error'\")\n",
    "else:\n",
    "    df = pd.read_json(ANNOTATION_FILE, lines=True)\n",
    "    # Create the full path to each image file\n",
    "    df['img_path'] = df['img'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "    print(\"Local dataset loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39640549",
   "metadata": {},
   "source": [
    "### Balanced Sampling Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9442261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df['label'].map({0: 'non-hateful', 1: 'hateful'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a5aceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hateful_df = df[df['label'] == 1].sample(n=20, random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e97b0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hateful_df = df[df['label'] == 0].sample(n=20, random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87a660b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.concat([hateful_df, non_hateful_df])\n",
    "df_sample = df_sample.sample(frac=1, random_state=50).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ce05edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56980</td>\n",
       "      <td>img/56980.png</td>\n",
       "      <td>0</td>\n",
       "      <td>coffee isn't helping get the jumper cables</td>\n",
       "      <td>data/img/img/56980.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28905</td>\n",
       "      <td>img/28905.png</td>\n",
       "      <td>1</td>\n",
       "      <td>hey, i just met you and this is crazy but here...</td>\n",
       "      <td>data/img/img/28905.png</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32415</td>\n",
       "      <td>img/32415.png</td>\n",
       "      <td>0</td>\n",
       "      <td>when finishing a race is your passion</td>\n",
       "      <td>data/img/img/32415.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97305</td>\n",
       "      <td>img/97305.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when your wife just died giving birth to your ...</td>\n",
       "      <td>data/img/img/97305.png</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63921</td>\n",
       "      <td>img/63921.png</td>\n",
       "      <td>0</td>\n",
       "      <td>taking a photo with family</td>\n",
       "      <td>data/img/img/63921.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  56980  img/56980.png      0   \n",
       "1  28905  img/28905.png      1   \n",
       "2  32415  img/32415.png      0   \n",
       "3  97305  img/97305.png      1   \n",
       "4  63921  img/63921.png      0   \n",
       "\n",
       "                                                text                img_path  \\\n",
       "0         coffee isn't helping get the jumper cables  data/img/img/56980.png   \n",
       "1  hey, i just met you and this is crazy but here...  data/img/img/28905.png   \n",
       "2              when finishing a race is your passion  data/img/img/32415.png   \n",
       "3  when your wife just died giving birth to your ...  data/img/img/97305.png   \n",
       "4                         taking a photo with family  data/img/img/63921.png   \n",
       "\n",
       "    label_text  \n",
       "0  non-hateful  \n",
       "1      hateful  \n",
       "2  non-hateful  \n",
       "3      hateful  \n",
       "4  non-hateful  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b52ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a balanced test set with 40 samples.\n",
      "Label distribution:\n",
      "label_text\n",
      "non-hateful    20\n",
      "hateful        20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created a balanced test set with {len(df_sample)} samples.\")\n",
    "print(\"Label distribution:\")\n",
    "print(df_sample['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5120da3",
   "metadata": {},
   "source": [
    "## Step 2: Playing with the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ff1d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt():\n",
    "    \"\"\"Asks for a direct classification.\"\"\"\n",
    "    return (\n",
    "    \"You are a content moderation AI. Your task is to classify a meme as either 'hateful' or 'non-hateful'. \"\n",
    "    \"Analyze both the image and the accompanying text.\\n\"\n",
    "    \"Respond in *exactly* this format (no explanation before or after):\\n\"\n",
    "    \"Classification: hateful or non-hateful\\n\"\n",
    "    \"Justification: <your short reason>\\n\"\n",
    "    \"Example:\\n\"\n",
    "    \"Classification: non-hateful\\n\"\n",
    "    \"Justification: The meme contains no offensive content and appears neutral.\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64cb6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt():\n",
    "    return (\n",
    "        \"You are a content moderation AI. Your task is to classify a meme as either **hateful** or **non-hateful**.\\n\"\n",
    "        \"Analyze both the **image** and any **text** it contains. Think step-by-step, then give your final answer.\\n\\n\"\n",
    "\n",
    "        \"Please follow the **exact format** below:\\n\"\n",
    "        \"Classification: <hateful|non-hateful>\\n\"\n",
    "        \"Justification: <1–2 sentence reason based on the image and/or text>\\n\\n\"\n",
    "\n",
    "        \"### EXAMPLES ###\\n\\n\"\n",
    "\n",
    "        \"Example 1:\\n\"\n",
    "        \"Image: A meme with a cartoon showing people of different races holding hands with the text: 'We’re stronger together.'\\n\"\n",
    "        \"Classification: non-hateful\\n\"\n",
    "        \"Justification: The image promotes unity and shows no offensive or targeted content.\\n\\n\"\n",
    "\n",
    "        \"Example 2:\\n\"\n",
    "        \"Image: A meme with a photo of a specific religion’s attire and a caption mocking it with slurs.\\n\"\n",
    "        \"Classification: hateful\\n\"\n",
    "        \"Justification: The image contains derogatory language targeting a religious group, making it hateful.\\n\\n\"\n",
    "\n",
    "        \"Example 3:\\n\"\n",
    "        \"Image: A meme with a man slipping on a banana peel with the caption: 'My Monday mornings.'\\n\"\n",
    "        \"Classification: non-hateful\\n\"\n",
    "        \"Justification: The image is humorous and contains no targeted or harmful content.\\n\\n\"\n",
    "\n",
    "        \"### NEW MEME ###\\n\"\n",
    "        \"Now analyze the following meme and provide your response in the same format.\\n\"\n",
    "        \"Respond only with:\\n\"\n",
    "        \"Classification: <hateful|non-hateful>\\n\"\n",
    "        \"Justification: <reason>\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a35f5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = create_zero_shot_prompt()\n",
    "prompt_template = create_few_shot_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93c4b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_response(response_text):\n",
    "#     cleaned_text = response_text.lower().strip()\n",
    "\n",
    "#     classification = 'error'\n",
    "#     justification = '' ''## will modify this later. Adding for debugging\n",
    "\n",
    "#     if 'justification:' in cleaned_text:\n",
    "#         try:\n",
    "#             parts = cleaned_text.split('justification:', 1)\n",
    "#             classification_part = parts[0]\n",
    "#             justification = parts[1].strip()\n",
    "#         except IndexError:\n",
    "#             classification_part = cleaned_text\n",
    "#             justification = \"Could not parse justification part.\"\n",
    "#     else:\n",
    "#         classification_part = cleaned_text\n",
    "\n",
    "#     if 'non-hateful' in classification_part:\n",
    "#         classification = 'non-hateful'\n",
    "#     elif 'hateful' in classification_part:\n",
    "#         classification = 'hateful'\n",
    "        \n",
    "#     return classification, justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e035e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse function v3\n",
    "import re\n",
    "\n",
    "def parse_response(response_text):\n",
    "    \"\"\"\n",
    "    A robust function to extract classification and justification using regular expressions.\n",
    "    \"\"\"\n",
    "    cleaned_text = response_text.lower().strip()\n",
    "\n",
    "    classification = 'error'\n",
    "    justification = ''\n",
    "\n",
    "    classification_match = re.search(r\"classification:\\s*(hateful|non-hateful)\", cleaned_text) \n",
    "    \n",
    "    if classification_match:\n",
    "        classification = classification_match.group(1).strip()\n",
    "    else:\n",
    "        if 'non-hateful' in cleaned_text:\n",
    "            classification = 'non-hateful'\n",
    "        elif 'hateful' in cleaned_text:\n",
    "            classification = 'hateful'\n",
    "\n",
    "    justification_match = re.search(r\"justification:\\s*(.*)\", cleaned_text, re.DOTALL)\n",
    "    if justification_match:\n",
    "        justification = justification_match.group(1).strip()\n",
    "    elif not justification and classification != 'error':\n",
    "        justification = \"Justification not provided in response.\"\n",
    "    else:\n",
    "        justification = cleaned_text # For 'error' cases, store the raw output for debugging\n",
    "\n",
    "    return classification, justification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71b5a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_response(response_text): v2\n",
    "#     cleaned_text = response_text.lower().strip()\n",
    "\n",
    "#     classification = 'error'\n",
    "#     justification = ''\n",
    "\n",
    "#     # Try to extract classification line\n",
    "#     if 'classification:' in cleaned_text:\n",
    "#         try:\n",
    "#             classification_line = cleaned_text.split('classification:')[1].split('\\n')[0].strip()\n",
    "#             if 'non-hateful' in classification_line:\n",
    "#                 classification = 'non-hateful'\n",
    "#             elif 'hateful' in classification_line:\n",
    "#                 classification = 'hateful'\n",
    "#         except Exception:\n",
    "#             classification = 'error'\n",
    "\n",
    "#     # Fallback: try first word\n",
    "#     # if classification == 'error':\n",
    "#     #     if cleaned_text.startswith('non-hateful'):\n",
    "#     #         classification = 'non-hateful'\n",
    "#     #     elif cleaned_text.startswith('hateful'):\n",
    "#     #         classification = 'hateful'\n",
    "\n",
    "#     # Extract justification\n",
    "#     if 'justification:' in cleaned_text:\n",
    "#         try:\n",
    "#             justification = cleaned_text.split('justification:')[1].strip()\n",
    "#         except IndexError:\n",
    "#             justification = 'Could not parse justification.'\n",
    "\n",
    "#     return classification, justification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2deadd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "340b7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b426c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_gemini(image_path, prompt):\n",
    "    \"\"\"Classifies a meme using the Gemini 1.5 Flash model.\"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return 'error', \"GOOGLE_API_KEY not configured.\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        safety_settings = {\n",
    "            'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',\n",
    "            'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',\n",
    "            'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'\n",
    "        }\n",
    "        \n",
    "        response = model.generate_content([prompt, img], safety_settings=safety_settings)\n",
    "        return parse_response(response.text)\n",
    "    except Exception as e:\n",
    "        return 'error', f\"Gemini API Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa6d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0729dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f90f6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9036d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmarking model: gemini-2.5-flash ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gemini-2.5-flash: 100%|██████████| 40/40 [00:58<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmark Complete! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label_text</th>\n",
       "      <th>prediction_gemini-2.5-flash</th>\n",
       "      <th>justification_gemini-2.5-flash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56980</td>\n",
       "      <td>img/56980.png</td>\n",
       "      <td>0</td>\n",
       "      <td>coffee isn't helping get the jumper cables</td>\n",
       "      <td>data/img/img/56980.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "      <td>Gemini API Error: 429 You exceeded your curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28905</td>\n",
       "      <td>img/28905.png</td>\n",
       "      <td>1</td>\n",
       "      <td>hey, i just met you and this is crazy but here...</td>\n",
       "      <td>data/img/img/28905.png</td>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "      <td>Gemini API Error: 429 You exceeded your curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32415</td>\n",
       "      <td>img/32415.png</td>\n",
       "      <td>0</td>\n",
       "      <td>when finishing a race is your passion</td>\n",
       "      <td>data/img/img/32415.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "      <td>Gemini API Error: 429 You exceeded your curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97305</td>\n",
       "      <td>img/97305.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when your wife just died giving birth to your ...</td>\n",
       "      <td>data/img/img/97305.png</td>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "      <td>Gemini API Error: 429 You exceeded your curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63921</td>\n",
       "      <td>img/63921.png</td>\n",
       "      <td>0</td>\n",
       "      <td>taking a photo with family</td>\n",
       "      <td>data/img/img/63921.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "      <td>Gemini API Error: 429 You exceeded your curren...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  56980  img/56980.png      0   \n",
       "1  28905  img/28905.png      1   \n",
       "2  32415  img/32415.png      0   \n",
       "3  97305  img/97305.png      1   \n",
       "4  63921  img/63921.png      0   \n",
       "\n",
       "                                                text                img_path  \\\n",
       "0         coffee isn't helping get the jumper cables  data/img/img/56980.png   \n",
       "1  hey, i just met you and this is crazy but here...  data/img/img/28905.png   \n",
       "2              when finishing a race is your passion  data/img/img/32415.png   \n",
       "3  when your wife just died giving birth to your ...  data/img/img/97305.png   \n",
       "4                         taking a photo with family  data/img/img/63921.png   \n",
       "\n",
       "    label_text prediction_gemini-2.5-flash  \\\n",
       "0  non-hateful                       error   \n",
       "1      hateful                       error   \n",
       "2  non-hateful                       error   \n",
       "3      hateful                       error   \n",
       "4  non-hateful                       error   \n",
       "\n",
       "                      justification_gemini-2.5-flash  \n",
       "0  Gemini API Error: 429 You exceeded your curren...  \n",
       "1  Gemini API Error: 429 You exceeded your curren...  \n",
       "2  Gemini API Error: 429 You exceeded your curren...  \n",
       "3  Gemini API Error: 429 You exceeded your curren...  \n",
       "4  Gemini API Error: 429 You exceeded your curren...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_test = {\n",
    "    'gemini-2.5-flash': classify_with_gemini\n",
    "}\n",
    "results_data = {model: [] for model in models_to_test}\n",
    "\n",
    "for model_name, classification_func in models_to_test.items():\n",
    "    print(f\"\\n--- Benchmarking model: {model_name} ---\")\n",
    "    predictions = []\n",
    "    justifications = []\n",
    "    for index, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=f\"Processing {model_name}\"):\n",
    "        pred, just = classification_func(row['img_path'], prompt_template)\n",
    "        predictions.append(pred)\n",
    "        justifications.append(just)\n",
    "\n",
    "    df_sample[f'prediction_{model_name}'] = predictions\n",
    "    df_sample[f'justification_{model_name}'] = justifications\n",
    "\n",
    "\n",
    "print(\"\\n--- Benchmark Complete! ---\")\n",
    "# display(df_sample[['id', 'label_text'] + [f'prediction_{model}' for model in models_to_test.keys()]].head())\n",
    "\n",
    "display(df_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b88a7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_sample['label_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "926e12f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Report for: gemini-2.5-flash ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.00      0.00      0.00      20.0\n",
      " non-hateful       0.00      0.00      0.00      20.0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for model_name in models_to_test.keys():\n",
    "    print(f\"\\n--- Evaluation Report for: {model_name} ---\")\n",
    "    model_predictions = df_sample[f'prediction_{model_name}']\n",
    "    model_predictions = model_predictions.apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "\n",
    "    report = classification_report(\n",
    "        ground_truth, \n",
    "        model_predictions, \n",
    "        labels=['hateful', 'non-hateful'], \n",
    "        zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a69f2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['id', 'text', 'label_text']\n",
    "for model_name in models_to_test.keys():\n",
    "    columns_to_keep.append(f'prediction_{model_name}')\n",
    "    columns_to_keep.append(f'justification_{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "972e7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = df_sample[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69940cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df.to_csv('gemini few shot.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
