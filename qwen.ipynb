{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f836d6b8",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This notebook implements an advanced benchmark of four distinct Vision Language Models (VLMs) on the Hateful Memes Challenge Dataset (HMCD). This version loads the dataset from local files, uses a balanced dataset sample, and evaluates models from four different families to capture classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f8235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0f59",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset from Local Files & Prepare Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdeb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'data' \n",
    "ANNOTATION_FILE = os.path.join(DATASET_FOLDER, 'dev.jsonl')\n",
    "IMG_DIR = os.path.join(DATASET_FOLDER, 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c0cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ANNOTATION_FILE):\n",
    "    print(f\"Error'\")\n",
    "else:\n",
    "    df = pd.read_json(ANNOTATION_FILE, lines=True)\n",
    "    # Create the full path to each image file\n",
    "    df['img_path'] = df['img'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "    print(\"Local dataset loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39640549",
   "metadata": {},
   "source": [
    "### Balanced Sampling Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9442261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df['label'].map({0: 'non-hateful', 1: 'hateful'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5aceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hateful_df = df[df['label'] == 1].sample(n=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97b0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hateful_df = df[df['label'] == 0].sample(n=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a660b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.concat([hateful_df, non_hateful_df])\n",
    "df_sample = df_sample.sample(frac=1, random_state=50).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce05edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39018</td>\n",
       "      <td>img/39018.png</td>\n",
       "      <td>0</td>\n",
       "      <td>she said \"i want a ring\" i said \"bitch take yo...</td>\n",
       "      <td>data/img/img/39018.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62703</td>\n",
       "      <td>img/62703.png</td>\n",
       "      <td>0</td>\n",
       "      <td>they shot the wrong gorilla</td>\n",
       "      <td>data/img/img/62703.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54129</td>\n",
       "      <td>img/54129.png</td>\n",
       "      <td>0</td>\n",
       "      <td>dump pipe to the ocean</td>\n",
       "      <td>data/img/img/54129.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1742</td>\n",
       "      <td>img/01742.png</td>\n",
       "      <td>0</td>\n",
       "      <td>in just one hour from now i'll only have 4 hou...</td>\n",
       "      <td>data/img/img/01742.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85237</td>\n",
       "      <td>img/85237.png</td>\n",
       "      <td>0</td>\n",
       "      <td>these are all the weapons that were seized fro...</td>\n",
       "      <td>data/img/img/85237.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  39018  img/39018.png      0   \n",
       "1  62703  img/62703.png      0   \n",
       "2  54129  img/54129.png      0   \n",
       "3   1742  img/01742.png      0   \n",
       "4  85237  img/85237.png      0   \n",
       "\n",
       "                                                text                img_path  \\\n",
       "0  she said \"i want a ring\" i said \"bitch take yo...  data/img/img/39018.png   \n",
       "1                        they shot the wrong gorilla  data/img/img/62703.png   \n",
       "2                             dump pipe to the ocean  data/img/img/54129.png   \n",
       "3  in just one hour from now i'll only have 4 hou...  data/img/img/01742.png   \n",
       "4  these are all the weapons that were seized fro...  data/img/img/85237.png   \n",
       "\n",
       "    label_text  \n",
       "0  non-hateful  \n",
       "1  non-hateful  \n",
       "2  non-hateful  \n",
       "3  non-hateful  \n",
       "4  non-hateful  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b52ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a balanced test set with 500 samples.\n",
      "Label distribution:\n",
      "label_text\n",
      "non-hateful    250\n",
      "hateful        250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created a balanced test set with {len(df_sample)} samples.\")\n",
    "print(\"Label distribution:\")\n",
    "print(df_sample['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5120da3",
   "metadata": {},
   "source": [
    "## Step 2: Playing with the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff1d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt():\n",
    "    \"\"\"Asks for a direct classification.\"\"\"\n",
    "    return (\n",
    "    \"You are a content moderation AI. Your task is to classify a meme as either 'hateful' or 'non-hateful'. \"\n",
    "    \"Analyze both the image and the accompanying text.\\n\"\n",
    "    \"Respond in *exactly* this format (no explanation before or after):\\n\"\n",
    "    \"Classification: hateful or non-hateful\\n\"\n",
    "    \"Justification: <your short reason>\\n\"\n",
    "    \"Example:\\n\"\n",
    "    \"Classification: non-hateful\\n\"\n",
    "    \"Justification: The meme contains no offensive content and appears neutral.\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64cb6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cot_prompt():\n",
    "    \"\"\"Guide the model to reason step-by-step before classifying.\"\"\"\n",
    "    return (\n",
    "        \"Perform the following steps:\\n\"\n",
    "        \"1. Briefly describe the visual elements in the image.\\n\"\n",
    "        \"2. Analyze the text on the meme.\\n\"\n",
    "        \"3. Consider the combined meaning of the visual elements and the text.\\n\\n\"\n",
    "        \"Based on your step-by-step analysis, classify the meme as 'hateful' or 'non-hateful'. \"\n",
    "        \"Your final response must be only the single word classification.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35f5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = create_zero_shot_prompt()\n",
    "# prompt_template = create_cot_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c4b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_response(response_text):\n",
    "#     cleaned_text = response_text.lower().strip()\n",
    "\n",
    "#     classification = 'error'\n",
    "#     justification = '' ''## will modify this later. Adding for debugging\n",
    "\n",
    "#     if 'justification:' in cleaned_text:\n",
    "#         try:\n",
    "#             parts = cleaned_text.split('justification:', 1)\n",
    "#             classification_part = parts[0]\n",
    "#             justification = parts[1].strip()\n",
    "#         except IndexError:\n",
    "#             classification_part = cleaned_text\n",
    "#             justification = \"Could not parse justification part.\"\n",
    "#     else:\n",
    "#         classification_part = cleaned_text\n",
    "\n",
    "#     if 'non-hateful' in classification_part:\n",
    "#         classification = 'non-hateful'\n",
    "#     elif 'hateful' in classification_part:\n",
    "#         classification = 'hateful'\n",
    "        \n",
    "#     return classification, justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e035e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse function v3\n",
    "import re\n",
    "\n",
    "def parse_response(response_text):\n",
    "    \"\"\"\n",
    "    A robust function to extract classification and justification using regular expressions.\n",
    "    \"\"\"\n",
    "    cleaned_text = response_text.lower().strip()\n",
    "\n",
    "    classification = 'error'\n",
    "    justification = ''\n",
    "\n",
    "    classification_match = re.search(r\"classification:\\s*(hateful|non-hateful)\", cleaned_text) \n",
    "    \n",
    "    if classification_match:\n",
    "        classification = classification_match.group(1).strip()\n",
    "    else:\n",
    "        if 'non-hateful' in cleaned_text:\n",
    "            classification = 'non-hateful'\n",
    "        elif 'hateful' in cleaned_text:\n",
    "            classification = 'hateful'\n",
    "\n",
    "    justification_match = re.search(r\"justification:\\s*(.*)\", cleaned_text, re.DOTALL)\n",
    "    if justification_match:\n",
    "        justification = justification_match.group(1).strip()\n",
    "    elif not justification and classification != 'error':\n",
    "        justification = \"Justification not provided in response.\"\n",
    "    else:\n",
    "        justification = cleaned_text # For 'error' cases, store the raw output for debugging\n",
    "\n",
    "    return classification, justification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b5a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_response(response_text): v2\n",
    "#     cleaned_text = response_text.lower().strip()\n",
    "\n",
    "#     classification = 'error'\n",
    "#     justification = ''\n",
    "\n",
    "#     # Try to extract classification line\n",
    "#     if 'classification:' in cleaned_text:\n",
    "#         try:\n",
    "#             classification_line = cleaned_text.split('classification:')[1].split('\\n')[0].strip()\n",
    "#             if 'non-hateful' in classification_line:\n",
    "#                 classification = 'non-hateful'\n",
    "#             elif 'hateful' in classification_line:\n",
    "#                 classification = 'hateful'\n",
    "#         except Exception:\n",
    "#             classification = 'error'\n",
    "\n",
    "#     # Fallback: try first word\n",
    "#     # if classification == 'error':\n",
    "#     #     if cleaned_text.startswith('non-hateful'):\n",
    "#     #         classification = 'non-hateful'\n",
    "#     #     elif cleaned_text.startswith('hateful'):\n",
    "#     #         classification = 'hateful'\n",
    "\n",
    "#     # Extract justification\n",
    "#     if 'justification:' in cleaned_text:\n",
    "#         try:\n",
    "#             justification = cleaned_text.split('justification:')[1].strip()\n",
    "#         except IndexError:\n",
    "#             justification = 'Could not parse justification.'\n",
    "\n",
    "#     return classification, justification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42344692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify_with_ollama(model_name, image_path, prompt):\n",
    "#     try:\n",
    "#         response = ollama.chat(\n",
    "#             model=model_name,\n",
    "#             messages=[{'role': 'user', 'content': prompt, 'images': [image_path]}]\n",
    "#         )\n",
    "#         content = response['message']['content']\n",
    "#         pred = parse_response(content)\n",
    "#         return pred, content\n",
    "#     except Exception as e:\n",
    "#         return 'error', 'error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a3e7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_ollama(model_name, image_path, prompt):\n",
    "    try:\n",
    "        response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt, 'images': [image_path]}])\n",
    "        return parse_response(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        return 'error', f\"Ollama API Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0729dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f90f6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9036d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmarking model: qwen2.5vl:7b ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing qwen2.5vl:7b: 100%|██████████| 500/500 [2:01:39<00:00, 14.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmark Complete! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label_text</th>\n",
       "      <th>prediction_qwen2.5vl:7b</th>\n",
       "      <th>justification_qwen2.5vl:7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39018</td>\n",
       "      <td>img/39018.png</td>\n",
       "      <td>0</td>\n",
       "      <td>she said \"i want a ring\" i said \"bitch take yo...</td>\n",
       "      <td>data/img/img/39018.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>the meme contains no offensive content and app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62703</td>\n",
       "      <td>img/62703.png</td>\n",
       "      <td>0</td>\n",
       "      <td>they shot the wrong gorilla</td>\n",
       "      <td>data/img/img/62703.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>the meme is a tribute to a gorilla and does no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54129</td>\n",
       "      <td>img/54129.png</td>\n",
       "      <td>0</td>\n",
       "      <td>dump pipe to the ocean</td>\n",
       "      <td>data/img/img/54129.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>the image and text do not contain any offensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1742</td>\n",
       "      <td>img/01742.png</td>\n",
       "      <td>0</td>\n",
       "      <td>in just one hour from now i'll only have 4 hou...</td>\n",
       "      <td>data/img/img/01742.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>the meme contains no offensive content and app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85237</td>\n",
       "      <td>img/85237.png</td>\n",
       "      <td>0</td>\n",
       "      <td>these are all the weapons that were seized fro...</td>\n",
       "      <td>data/img/img/85237.png</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>the meme depicts a collection of weapons seize...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  39018  img/39018.png      0   \n",
       "1  62703  img/62703.png      0   \n",
       "2  54129  img/54129.png      0   \n",
       "3   1742  img/01742.png      0   \n",
       "4  85237  img/85237.png      0   \n",
       "\n",
       "                                                text                img_path  \\\n",
       "0  she said \"i want a ring\" i said \"bitch take yo...  data/img/img/39018.png   \n",
       "1                        they shot the wrong gorilla  data/img/img/62703.png   \n",
       "2                             dump pipe to the ocean  data/img/img/54129.png   \n",
       "3  in just one hour from now i'll only have 4 hou...  data/img/img/01742.png   \n",
       "4  these are all the weapons that were seized fro...  data/img/img/85237.png   \n",
       "\n",
       "    label_text prediction_qwen2.5vl:7b  \\\n",
       "0  non-hateful             non-hateful   \n",
       "1  non-hateful             non-hateful   \n",
       "2  non-hateful             non-hateful   \n",
       "3  non-hateful             non-hateful   \n",
       "4  non-hateful             non-hateful   \n",
       "\n",
       "                          justification_qwen2.5vl:7b  \n",
       "0  the meme contains no offensive content and app...  \n",
       "1  the meme is a tribute to a gorilla and does no...  \n",
       "2  the image and text do not contain any offensiv...  \n",
       "3  the meme contains no offensive content and app...  \n",
       "4  the meme depicts a collection of weapons seize...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_test = {\n",
    "    'qwen2.5vl:7b': classify_with_ollama\n",
    "}\n",
    "results_data = {model: [] for model in models_to_test}\n",
    "\n",
    "for model_name, classification_func in models_to_test.items():\n",
    "    print(f\"\\n--- Benchmarking model: {model_name} ---\")\n",
    "    predictions = []\n",
    "    justifications = []\n",
    "    for index, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=f\"Processing {model_name}\"):\n",
    "        pred, just = classification_func(model_name, row['img_path'], prompt_template)\n",
    "        predictions.append(pred)\n",
    "        justifications.append(just)\n",
    "\n",
    "    df_sample[f'prediction_{model_name}'] = predictions\n",
    "    df_sample[f'justification_{model_name}'] = justifications\n",
    "\n",
    "# for model_name, data in results_data.items():\n",
    "#     df_sample[f'prediction_{model_name}'] = [item['prediction'] for item in data]\n",
    "#     df_sample[f'justification_{model_name}'] = [item['justification'] for item in data]\n",
    "\n",
    "#     df_sample['prediction_{model_name}'] = df_sample['prediction_{model_name}'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "#     df_sample['justification_{model_name}'] = df_sample['justification_{model_name}'].apply(lambda x: x[1] if isinstance(x, tuple) else x)\n",
    "\n",
    "\n",
    "print(\"\\n--- Benchmark Complete! ---\")\n",
    "# display(df_sample[['id', 'label_text'] + [f'prediction_{model}' for model in models_to_test.keys()]].head())\n",
    "\n",
    "display(df_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b88a7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_sample['label_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "926e12f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Report for: qwen2.5vl:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     hateful       0.70      0.34      0.45       250\n",
      " non-hateful       0.56      0.86      0.68       250\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.63      0.60      0.57       500\n",
      "weighted avg       0.63      0.60      0.57       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for model_name in models_to_test.keys():\n",
    "    print(f\"\\n--- Evaluation Report for: {model_name} ---\")\n",
    "    model_predictions = df_sample[f'prediction_{model_name}']\n",
    "    model_predictions = model_predictions.apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "\n",
    "    report = classification_report(\n",
    "        ground_truth, \n",
    "        model_predictions, \n",
    "        labels=['hateful', 'non-hateful'], \n",
    "        zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a23896d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_errors_with_justification(model_name):\n",
    "#     error_df = df_sample[df_sample['label_text'] != df_sample[f'prediction_{model_name}']]\n",
    "#     print(f\"\\n--- Error Analysis for {model_name} ---\")\n",
    "#     print(f\"Found {len(error_df)} errors out of {len(df_sample)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a69f2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['id', 'text', 'label_text']\n",
    "for model_name in models_to_test.keys():\n",
    "    columns_to_keep.append(f'prediction_{model_name}')\n",
    "    columns_to_keep.append(f'justification_{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "972e7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = df_sample[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69940cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df.to_csv('full_benchmark_results with justification qwen.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
