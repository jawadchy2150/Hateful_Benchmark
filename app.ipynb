{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f836d6b8",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This notebook implements an advanced benchmark of four distinct Vision Language Models (VLMs) on the Hateful Memes Challenge Dataset (HMCD). This version loads the dataset from local files, uses a balanced dataset sample, and evaluates models from four different families to capture classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569055ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e74200",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f6f8235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0f59",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset from Local Files & Prepare Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4fdeb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'data' \n",
    "ANNOTATION_FILE = os.path.join(DATASET_FOLDER, 'dev.jsonl')\n",
    "IMG_DIR = os.path.join(DATASET_FOLDER, 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f9c0cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ANNOTATION_FILE):\n",
    "    print(f\"Error'\")\n",
    "else:\n",
    "    df = pd.read_json(ANNOTATION_FILE, lines=True)\n",
    "\n",
    "    # Create the full path to each image file\n",
    "    df['img_path'] = df['img'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "    print(\"Local dataset loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39640549",
   "metadata": {},
   "source": [
    "### Balanced Sampling Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9442261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df['label'].map({0: 'non-hateful', 1: 'hateful'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4a5aceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hateful_df = df[df['label'] == 1].sample(n=250, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e97b0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hateful_df = df[df['label'] == 0].sample(n=250, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "87a660b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.concat([hateful_df, non_hateful_df])\n",
    "df_sample = df_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_sample['img_path'] = df_sample['img_path'].apply(os.path.normpath) # Normalize all image paths to match your OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0ce05edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85237</td>\n",
       "      <td>img/85237.png</td>\n",
       "      <td>0</td>\n",
       "      <td>these are all the weapons that were seized fro...</td>\n",
       "      <td>data\\img\\img\\85237.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28017</td>\n",
       "      <td>img/28017.png</td>\n",
       "      <td>1</td>\n",
       "      <td>say it! say it ! islam is the religion of peace</td>\n",
       "      <td>data\\img\\img\\28017.png</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32875</td>\n",
       "      <td>img/32875.png</td>\n",
       "      <td>0</td>\n",
       "      <td>if he wears number one he's most likely the fa...</td>\n",
       "      <td>data\\img\\img\\32875.png</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834</td>\n",
       "      <td>img/12834.png</td>\n",
       "      <td>1</td>\n",
       "      <td>in west philadelphia, born and raised in the a...</td>\n",
       "      <td>data\\img\\img\\12834.png</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43810</td>\n",
       "      <td>img/43810.png</td>\n",
       "      <td>1</td>\n",
       "      <td>how to cook turkey in usa how to cook turkey i...</td>\n",
       "      <td>data\\img\\img\\43810.png</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  85237  img/85237.png      0   \n",
       "1  28017  img/28017.png      1   \n",
       "2  32875  img/32875.png      0   \n",
       "3  12834  img/12834.png      1   \n",
       "4  43810  img/43810.png      1   \n",
       "\n",
       "                                                text                img_path  \\\n",
       "0  these are all the weapons that were seized fro...  data\\img\\img\\85237.png   \n",
       "1    say it! say it ! islam is the religion of peace  data\\img\\img\\28017.png   \n",
       "2  if he wears number one he's most likely the fa...  data\\img\\img\\32875.png   \n",
       "3  in west philadelphia, born and raised in the a...  data\\img\\img\\12834.png   \n",
       "4  how to cook turkey in usa how to cook turkey i...  data\\img\\img\\43810.png   \n",
       "\n",
       "    label_text  \n",
       "0  non-hateful  \n",
       "1      hateful  \n",
       "2  non-hateful  \n",
       "3      hateful  \n",
       "4      hateful  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b52ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a balanced test set with 500 samples.\n",
      "Label distribution:\n",
      "label_text\n",
      "non-hateful    250\n",
      "hateful        250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created a balanced test set with {len(df_sample)} samples.\")\n",
    "print(\"Label distribution:\")\n",
    "print(df_sample['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5120da3",
   "metadata": {},
   "source": [
    "## Step 2: Playing with the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ff1d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shot_prompt():\n",
    "    \"\"\"Asks for a direct classification.\"\"\"\n",
    "    return (\n",
    "        \"You are an expert content moderation analyst. Classify the provided meme as either 'hateful' or 'non-hateful'.\\n\"\n",
    "        \"Respond with only a single word: `hateful` or `non-hateful`.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64cb6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cot_prompt():\n",
    "    \"\"\"Guide the model to reason step-by-step before classifying.\"\"\"\n",
    "    return (\n",
    "        \"Perform the following steps:\\n\"\n",
    "        \"1. Briefly describe the visual elements in the image.\\n\"\n",
    "        \"2. Analyze the text on the meme.\\n\"\n",
    "        \"3. Consider the combined meaning of the visual elements and the text.\\n\\n\"\n",
    "        \"Explain your step-by-step analysis and classify the meme as 'hateful' or 'non-hateful'. \"\n",
    "        \"Conclude your analysis with a single word classification.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a35f5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = create_zero_shot_prompt()\n",
    "# prompt_template = create_cot_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93c4b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response_text):\n",
    "    cleaned_text = response_text.lower().strip().replace('.', '')\n",
    "    if 'non-hateful' in cleaned_text:\n",
    "        return 'non-hateful'\n",
    "    elif 'hateful' in cleaned_text:\n",
    "        return 'hateful'\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b3c39d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server is running\n"
     ]
    }
   ],
   "source": [
    "#Test Ollama Server\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    r = requests.get(\"http://localhost:11434\")\n",
    "    print(\"Ollama server is running\")\n",
    "except Exception as e:\n",
    "    print(\"Ollama is not running:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the image, a person is seen skydiving from a Cessna aircraft. The individual, clad in a black helmet, has their arms outstretched as if embracing the thrill of the jump. The plane, painted in white and blue, is captured mid-flight against a backdrop of a clear blue sky. On the right side of the image, there's a text that humorously suggests that when the dive instructor starts yelling in Arabic, it's time to start crying for your life. The person appears to be having an enjoyable and adrenaline-filled experience, as indicated by their wide grin. \n"
     ]
    }
   ],
   "source": [
    "# def test_image_only(image_path):\n",
    "#     import base64, requests\n",
    "\n",
    "#     with open(image_path, \"rb\") as img:\n",
    "#         image_data = base64.b64encode(img.read()).decode(\"utf-8\")\n",
    "\n",
    "#     response = requests.post(\n",
    "#         \"http://localhost:11434/api/generate\",\n",
    "#         json={\n",
    "#             \"model\": \"llava:7b\",\n",
    "#             \"prompt\": \"Describe everything in this image.\",\n",
    "#             \"images\": [image_data],\n",
    "#             \"stream\": False\n",
    "#         }\n",
    "#     )\n",
    "#     print(response.json()[\"response\"])\n",
    "\n",
    "# test_image_only(\"data\\img\\98714.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a61c8adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Response:  Non-hateful \n"
     ]
    }
   ],
   "source": [
    "# Test for single image\n",
    "\n",
    "# import base64\n",
    "# import requests\n",
    "\n",
    "# model_name = \"llava:7b\"\n",
    "# image_path = \"data\\img\\\\28017.png\"  # Use an actual file path here\n",
    "# prompt = \"What is in this image?\"\n",
    "\n",
    "# def test_llava(model_name, image_path, prompt):\n",
    "#     try:\n",
    "#         with open(image_path, \"rb\") as f:\n",
    "#             image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "#         response = requests.post(\n",
    "#             \"http://localhost:11434/api/generate\",\n",
    "#             json={\n",
    "#                 \"model\": model_name,\n",
    "#                 \"prompt\": prompt,\n",
    "#                 \"images\": [image_data],\n",
    "#                 \"stream\": False\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         print(\"✅ Response:\", response.json()[\"response\"])\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Error:\", e)\n",
    "\n",
    "# test_llava(model_name, image_path, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb553057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "def classify_with_ollama(model_name, image_path, prompt):\n",
    "    try:\n",
    "        # Read and encode the image\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "        # Send HTTP request to Ollama API\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": model_name,\n",
    "                \"prompt\": prompt,\n",
    "                \"images\": [image_data],\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "\n",
    "        result = response.json()[\"response\"]\n",
    "\n",
    "        # You can still use parse_response if needed:\n",
    "        return parse_response(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "42344692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify_with_ollama(model_name, image_path, prompt):\n",
    "#     try:\n",
    "#         response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt, 'images': [image_path]}])\n",
    "#         return parse_response(response['message']['content'])\n",
    "#     except Exception as e:\n",
    "#         return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa6d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f90f6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "adf9f756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Missing image files:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85237</td>\n",
       "      <td>data\\img\\img/85237.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28017</td>\n",
       "      <td>data\\img\\img/28017.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32875</td>\n",
       "      <td>data\\img\\img/32875.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834</td>\n",
       "      <td>data\\img\\img/12834.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43810</td>\n",
       "      <td>data\\img\\img/43810.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>95640</td>\n",
       "      <td>data\\img\\img/95640.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32579</td>\n",
       "      <td>data\\img\\img/32579.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>38095</td>\n",
       "      <td>data\\img\\img/38095.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>30586</td>\n",
       "      <td>data\\img\\img/30586.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1726</td>\n",
       "      <td>data\\img\\img/01726.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                img_path\n",
       "0    85237  data\\img\\img/85237.png\n",
       "1    28017  data\\img\\img/28017.png\n",
       "2    32875  data\\img\\img/32875.png\n",
       "3    12834  data\\img\\img/12834.png\n",
       "4    43810  data\\img\\img/43810.png\n",
       "..     ...                     ...\n",
       "495  95640  data\\img\\img/95640.png\n",
       "496  32579  data\\img\\img/32579.png\n",
       "497  38095  data\\img\\img/38095.png\n",
       "498  30586  data\\img\\img/30586.png\n",
       "499   1726  data\\img\\img/01726.png\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check which files don't exist\n",
    "missing_files = df_sample[~df_sample['img_path'].apply(os.path.exists)]\n",
    "\n",
    "if not missing_files.empty:\n",
    "    print(\"❌ Missing image files:\")\n",
    "    display(missing_files[['id', 'img_path']])\n",
    "else:\n",
    "    print(\"✅ All image paths are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a9036d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmarking model: llava:7b ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing llava:7b: 100%|██████████| 500/500 [00:00<00:00, 3496.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmark Complete! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_text</th>\n",
       "      <th>prediction_llava:7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85237</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error: [Errno 2] No such file or directory: 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28017</td>\n",
       "      <td>hateful</td>\n",
       "      <td>error: [Errno 2] No such file or directory: 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32875</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error: [Errno 2] No such file or directory: 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12834</td>\n",
       "      <td>hateful</td>\n",
       "      <td>error: [Errno 2] No such file or directory: 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43810</td>\n",
       "      <td>hateful</td>\n",
       "      <td>error: [Errno 2] No such file or directory: 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   label_text                                prediction_llava:7b\n",
       "0  85237  non-hateful  error: [Errno 2] No such file or directory: 'd...\n",
       "1  28017      hateful  error: [Errno 2] No such file or directory: 'd...\n",
       "2  32875  non-hateful  error: [Errno 2] No such file or directory: 'd...\n",
       "3  12834      hateful  error: [Errno 2] No such file or directory: 'd...\n",
       "4  43810      hateful  error: [Errno 2] No such file or directory: 'd..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_test = {\n",
    "    'llava:7b': classify_with_ollama\n",
    "}\n",
    "results_data = {model: [] for model in models_to_test}\n",
    "\n",
    "for model_name, classification_func in models_to_test.items():\n",
    "    print(f\"\\n--- Benchmarking model: {model_name} ---\")\n",
    "    predictions = []\n",
    "    for index, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=f\"Processing {model_name}\"):\n",
    "        if 'ollama' in classification_func.__name__:\n",
    "            pred = classification_func(model_name, row['img_path'], prompt_template)\n",
    "        else:\n",
    "            pred = classification_func(row['img_path'], prompt_template) ## for gemini or claude\n",
    "        predictions.append(pred)\n",
    "    df_sample[f'prediction_{model_name}'] = predictions\n",
    "\n",
    "print(\"\\n--- Benchmark Complete! ---\")\n",
    "display(df_sample[['id', 'label_text'] + [f'prediction_{model}' for model in models_to_test.keys()]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b88a7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_sample['label_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "926e12f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.strings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-a9622bb96a6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels_to_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n--- Evaluation Report for: {model_name} ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'prediction_{model_name}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# deprecate callable objects, skipping classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_key\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_num\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0m_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0m_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0muse_hugepage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         \u001b[0muse_hugepage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_hugepage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[1;31m# Note that this will currently only make a difference on Linux\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.strings'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for model_name in models_to_test.keys():\n",
    "    print(f\"\\n--- Evaluation Report for: {model_name} ---\")\n",
    "    model_predictions = df_sample[f'prediction_{model_name}']\n",
    "    report = classification_report(ground_truth, model_predictions, labels=['hateful', 'non-hateful'], zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a69f2d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_text</th>\n",
       "      <th>prediction_llava:7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>non-hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>hateful</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_text prediction_llava:7b\n",
       "0    non-hateful               error\n",
       "1        hateful               error\n",
       "2    non-hateful               error\n",
       "3        hateful               error\n",
       "4        hateful               error\n",
       "..           ...                 ...\n",
       "495      hateful               error\n",
       "496  non-hateful               error\n",
       "497  non-hateful               error\n",
       "498  non-hateful               error\n",
       "499      hateful               error\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_show = ['label_text'] + [col for col in df_sample.columns if 'prediction' in col]\n",
    "full_results_df = df_sample[columns_to_show]\n",
    "display(full_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69940cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df.to_csv('full_benchmark_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
